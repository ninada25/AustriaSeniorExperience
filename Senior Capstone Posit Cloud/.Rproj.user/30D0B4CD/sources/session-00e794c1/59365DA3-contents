---
title: "SE Work"
output: html_document
date: "2024-01-10"
---
```{r setup, include = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, include = TRUE, warning = FALSE)
```

```{r}
library(tidyverse)
library(readr)
library(knitr)
library(ggplot2)
library(dplyr)
library(maps)
library(Lock5Data)
library(gridExtra)
library(lme4)
library(lmerTest)
library(Matrix)
```

```{r, echo=FALSE}
#setwd("/cloud/project/data")
happy <- read_csv("hapiscore2018.csv") # only want to look at happiness scores for 2018 since the other dataset I will work with contains data from 2018

data("AllCountries")

### DATA CLEANING - World Happiness Report 2018 ### 

summary(happy)
happy[sapply(happy, is.character)] <- lapply(happy[sapply(happy, is.character)], as.factor) # convert all character variables to factor
happy$`Perceptions of corruption` <- as.numeric(as.character(happy$`Perceptions of corruption`)) # convert perceptions of corruption to numeric
glimpse(happy)
colnames(happy) <- gsub(" ", "_", colnames(happy)) # replace all spaces in column names with underscores
n_distinct(happy$Country_or_region) # 156 different countries or regions

### DATA CLEANING - AllCountries (data for each variable were collected for 2018 (or most recently available year) ###

summary(AllCountries)
n_distinct(AllCountries$Country) # 217 different countries in this dataset, I will only look at the places that also have a happiness score in the other dataset

### CREATING A MERGED DATASET 

# Merge two datasets
countries_with_happy <- merge(happy, AllCountries, by.x = "Country_or_region", by.y = "Country") 

# Call column '2018' 'Happiness_score'
colnames(countries_with_happy)[colnames(countries_with_happy) == "Score"] <- "Happiness_score" 

summary(countries_with_happy)
glimpse(countries_with_happy)
n_distinct(countries_with_happy$Country_or_region) # 137 countries in final dataset

# Selecting a subset of the data
countries_with_happy <- countries_with_happy[, c("Happiness_score", "Country_or_region", "GDP", "Military", "Health", "Internet", "Unemployment")]
```

Last week, I created graphs and tables summarizing my data.

# Graphs and Tables Summarizing Data

```{r}
# Histogram of happiness scores 
ggplot(data=countries_with_happy, aes(x=Happiness_score)) + 
  geom_histogram(fill="purple", color="white") + 
  ggtitle("Distribution of Happiness Scores") +
  xlab("Happiness Score (0-10)") + 
  ylab("Frequency")
```

The histogram shows us the distribution of happiness scores. More than 12 countries have a score of around 4.4, and many countries have scores between 5 and 6.5. A couple of countries have scores close to 3, while a few have scores of 8 or above. (Note: Happiness score is the national average response to the question of life evaluations asking "Please imagine a ladder, with steps numbered from 0 at the bottom to 10 at the top. The top of the ladder represents the best possible life for you and the bottom of the ladder represents the worst possible life for you. On which step of the ladder would you say you personally feel you stand at this time?" This measure is also referred to as Cantril life ladder.)

```{r}
# Scatterplot of happiness score VS GDP per capita
ggplot(data=countries_with_happy, aes(x=GDP, y=Happiness_score)) + 
  geom_point() +
  ggtitle("GDP VS Happiness Score") + 
  ylab("Happiness Score (0-10)") + 
  xlab("GDP per capita") 
```

Overall, there is an upward trend, indicating that countries or regions with higher GDP tend to, on average, have higher happiness scores, and there seems to be some curvature here. There is a good amount of variability in happiness scores for countries with very low GDPs. For countries with GDPs close to 0 (i.e. in the low hundreds of US$), happiness scores range from below 3 to above 6. Note also that 4 countries with GDPs of above \$60,000 have happiness scores below 7.

For the data points that have GDP per capita very close to 0, this implies either an extremely low or non-exist GDP (total economic output) or a very large population relative to the economic output. Burundi has a GDP per capita of $275.

It seems like a log transform on GDP might be a good thing to include in my model.

```{r}
library(corrplot)

# Correlation plot for numerical variables in the dataset:
Corr <- cor(select_if(countries_with_happy, is.numeric), use="complete.obs")
corrplot(Corr)
```

Happiness score seems to have a fairly high positive correlation with GDP which is consistent with what I found in my scatterplot above. Happiness score also has fairly high positive correlations with percentage of government expenditures directed towards healthcare and percentage of the population with access to the internet. Happiness score has a weak negative correlation with unemployment, but it also has a weak negative correlation with percentage of government expenditures directed toward the military, which is interesting and might be something worth looking into.

```{r}
# Sorting the Data by GDP and Selecting the 10 Lowest GDPs
lowest_gdp_data <- countries_with_happy[order(countries_with_happy$GDP), ][1:10,]

# Creating a Horizontal Bar Chart of Happiness Scores for the 10 Countries with the Lowest GDPs
ggplot(lowest_gdp_data, aes(x = Happiness_score, y = reorder(Country_or_region, GDP), fill = GDP)) +
  scale_fill_gradient(low = "lightblue", high = "dodgerblue") + 
  geom_bar(stat = "identity") +
  labs(title = "Happiness Scores for the 10 Countries/Regions with the Lowest GDPs", x = "Happiness Score (0-10)", y = "Country or Region") +
  xlim(0,10) + # setting scale for x axis
  theme_minimal() +
  theme(axis.text = element_text(size = 10)) +
  geom_label(mapping = aes(label = Happiness_score))
```

```{r}
# Sorting the Data by GDP and Selecting the 10 Highest GDPs
highest_gdp_data <- countries_with_happy[order(countries_with_happy$GDP, decreasing = TRUE), ][1:10,]

# Creating a Horizontal Bar Chart of Happiness Scores for the 10 Countries with the Lowest GDPs
ggplot(highest_gdp_data, aes(x = Happiness_score, y = reorder(Country_or_region, GDP), fill = GDP)) +
  scale_fill_gradient(low = "lightblue", high = "dodgerblue") + 
  geom_bar(stat = "identity") +
  labs(title = "Happiness Scores for the 10 Countries/Regions with the Highest GDPs", x = "Happiness Score (0-10)", y = "Country or Region") +
  xlim(0,10) + # setting scale for x axis
  theme_minimal() +
  theme(axis.text = element_text(size = 10)) +
  geom_label(mapping = aes(label = Happiness_score))
```

For the countries or regions with the 10 lowest GDPs in our dataset, happiness scores range from 2.905 to 4.982. Burundi, which has the lowest GDP of all countries and regions in our dataset, has the lowest happiness score of these 10 places. For the countries or regions with the 10 highest GDPs in our dataset, happiness scores range from 6.343 to 7.594. It is interesting that the country with the highest GDP has a lower happiness score than 6 of the countries or regions here.

```{r}
# Scatterplot of happiness score VS military
ggplot(data=countries_with_happy, aes(x=Military, y=Happiness_score)) + 
  geom_point() +
  ggtitle("% Gov Expenditures Directed Toward Military VS Happiness Score") + 
  ylab("Happiness Score (0-10)") + 
  xlab("% Gov Expenditures Directed Toward Military") +
  geom_smooth(method = "lm", se = FALSE)
```

There seems to be a weak, negative linear relationship between percentage of government expenditures directed toward the military and happiness score, which is interesting. With that being said, there is a lot of variability in happiness scores among countries with lower percentages of government expenditures directed toward the military (i.e. less than 10%), with some countries having scores below 3.5 and others having scores above 7.5.

```{r}
# Scatterplot of happiness score VS unemployment
ggplot(data=countries_with_happy, aes(x=Unemployment, y=Happiness_score)) + 
  geom_point() +
  ggtitle("Unemployment VS Happiness Score") + 
  ylab("Happiness Score (0-10)") + 
  xlab("% Labor Force Unemployed") +
  geom_smooth(method = "lm", se = FALSE)
```

There also seems to be a weak, negative linear relationship between percent of the labor force unemployed and happiness score. It is interesting that there is more variability in happiness scores among countries with a smaller percentage of the labor force unemployed.

------------------------------------------------------------------------------------------------------------------------------------------------------------------

# Weeks 2-4 Work:

```{r}
ggplot(data=countries_with_happy, aes(x = GDP, y = Happiness_score)) + 
  geom_point() +
  stat_smooth(method="lm", se=FALSE) + 
  ggtitle("Happines Score VS GDP") + 
  xlab("GDP") + ylab("Happiness Score (0-10)") 

ggplot(data=countries_with_happy, aes(x = Internet, y = Happiness_score)) + geom_point() +
  stat_smooth(method="lm", se=FALSE) + 
  ggtitle("Happiness Score VS % Population with Access to Internet") + 
  xlab("% Population with Access to Internet") + ylab("Happiness Score (0-10)") 
```

From the first graph, it looks like we might want to include a log transform on GDP to address the right-skewness! It seems like there are just a few countries with really big GDPs.

Fitting a simple linear regression model with log(GDP) as the only explanatory variable to the data, we obtain the following:

```{r}
Happy_M1 <- lm(data=countries_with_happy, Happiness_score~log(GDP))
summary(Happy_M1)
```

72.57%% of the total variation in happiness score is explained by log(GDP). 

```{r}
Corr
```

GDP and Internet have a correlation of around 0.713, so we should check to see if SE on log(GDP) increases significantly after adding Internet to our model. 

```{r}
Happy_GDPInternet <- lm(data=countries_with_happy, Happiness_score~log(GDP)+Internet)
summary(Happy_GDPInternet)
```

The SE on log(GDP) increased from <2e-16 to 3.88e-09, which is not that much. Thus, it should be fine to include both log(GDP) and Internet in the model. 73.03% of the total variation in happiness score is explained by log(GDP) and Internet.

Let us investigate whether there is an interaction between log(GDP) and Internet via scatterplot:

```{r}
# Scatterplot of happiness score VS GDP per capita with color = Internet
ggplot(data=countries_with_happy, aes(x=log(GDP), y=Happiness_score, color = Internet)) + 
  geom_point() +
  ggtitle("log(GDP) VS Happiness Score") + 
  ylab("Happiness Score (0-10)") + 
  xlab("log(GDP per capita)") 
```

I also created a categorical variable for Internet to further investigate the possibility of an interaction between log(GDP) and Internet:

```{r}
# Creating a categorical variable for Internet:
countries_with_happy$Internet_Categorical <- cut(countries_with_happy$Internet, breaks = c(0, 50, 100), labels = c("0-50", "50-100"))

# New ggplot
ggplot(data = countries_with_happy, aes(x = log(GDP), y = Happiness_score, color = Internet_Categorical)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, aes(group = Internet_Categorical)) +
  ggtitle("log(GDP) VS Happiness Score") + 
  ylab("Happiness Score (0-10)") + 
  xlab("log(GDP per capita)")
```

When I take the log of GDP, we get a really nice positive linear trend. There doesn't seem to be as much of a need for an interaction. I can look at a model with the interaction term and see what the p-value is. This is a case where looking at p-values might actually prove to be helpful.

```{r}
# checking p-value on interaction term between log(GDP) and Internet
Happy_GDPInternet <- lm(data=countries_with_happy, Happiness_score~log(GDP)*Internet)
summary(Happy_GDPInternet)
```

The p-value on the interaction term between log(GDP) and Internet is quite large, so I will proceed without interaction. Let us try adding Health to the model.

```{r}
Happy_M3 <- lm(data=countries_with_happy, Happiness_score~log(GDP)+Internet+Health)
summary(Happy_M3)
```

76.37% of the total variation in happiness score is explained by log(GDP), Internet, and Health. Let's try adding Military and Unemployment into our model as well:

```{r}
Happy_M4 <- lm(data=countries_with_happy, Happiness_score~log(GDP)+Internet+Health+Military+Unemployment)
summary(Happy_M4)
```

R^2 increased from 0.7637 to 0.8252.

Now let's check our model assumptions:

```{r, fig.width = 15}
P1 <- ggplot(data=data.frame(Happy_M4$residuals), aes(y=Happy_M4$residuals, x=Happy_M4$fitted.values)) + geom_point() + ggtitle("Residual Plot") + xlab("Predicted Values") + ylab("Residuals")
P2 <- ggplot(data=data.frame(Happy_M4$residuals), aes(x=Happy_M4$residuals)) + geom_histogram() + ggtitle("Histogram of Residuals") + xlab("Residual")
P3 <- ggplot(data=data.frame(Happy_M4$residuals), aes(sample = scale(Happy_M4$residuals))) + stat_qq() + stat_qq_line() + xlab("Normal Quantiles") + ylab("Residual Quantiles") + ggtitle("QQ Plot")
grid.arrange(P1, P2, P3, ncol=3)
```

We do not see any curvature or funnel shapes in the residual plot, so the linearity and constant variance assumptions seem valid. There is a slight left-skewness in our histogram of residuals and QQ plot, but it doesn’t appear too significant. This may raise some concern about the normality assumption, although, again, I don't think we need to worry too much about it. Usually, log transformations are useful for reducing numbers and addressing right skewness, but in our case, we want the opposite effect. I did a bit of research on addressing left-skewness, and it looks like some methods to try are (once again) log transformations, square root transformations, and removing outliers. However, given the non-severity of the skewness for now, I will maintain our model as it is.

With regards to the independence assumption, we must think about whether there were factors in the data collection that would cause some observations to be more highly correlated than others. There's a possibility that countries or regions in the same region or continent are more highly correlated. I might need to think about a model that can account for spatial correlation. I can try adding in a random effect for region, or perhaps learning more about spatial models and doing something with them.

In models with multiple explanatory variables, it is helpful to also plot our residuals against the explanatory variables to see whether the model is properly accounting for relationships involving each variable. If we see nonlinear trends, we should consider adding a nonlinear function of that explanatory variable.

```{r, fig.width = 20}
P4 <- ggplot(data=data.frame(Happy_M4$residuals), aes(y=Happy_M4$residuals, x=Happy_M4$model$`log(GDP)`)) + geom_point() + ggtitle("Residual by Predictor Plot") + xlab("GDP per capita") + ylab("Residuals")
P5 <- ggplot(data=data.frame(Happy_M4$residuals), aes(y=Happy_M4$residuals, x=Happy_M4$model$Internet)) + geom_point() + ggtitle("Residual by Predictor Plot") + xlab("% Pop With Access to Internet") + ylab("Residuals")
P6 <- ggplot(data=data.frame(Happy_M4$residuals), aes(y=Happy_M4$residuals, x=Happy_M4$model$Health)) + geom_point() + ggtitle("Residual by Predictor Plot") + xlab("% Gov Exp Dir Towards Healthcare") + ylab("Residuals")
P7 <- ggplot(data=data.frame(Happy_M4$residuals), aes(y=Happy_M4$residuals, x=Happy_M4$model$Military)) + geom_point() + ggtitle("Residual by Predictor Plot") + xlab("% Gov Exp Dir Towards Military") + ylab("Residuals")
P8 <- ggplot(data=data.frame(Happy_M4$residuals), aes(y=Happy_M4$residuals, x=Happy_M4$model$Unemployment)) + geom_point() + ggtitle("Residual by Predictor Plot") + xlab("% Labor Force Unemployed") + ylab("Residuals")
grid.arrange(P4, P5, P6, P7, P8, ncol=3)
```

There is some concern about the constant variance assumption in the plots of residuals against 'Military' and 'Unemployed.' However, there really are just a few points to the right that might add to this effect; it is nothing too serious. It is worth noting that this violation of the constant variance assumption could potentially lead to wider intervals, but the predictions should still be reliable. The linearity assumption looks good here; there is not really any curvature in our residual plots. 

Generally, if these looked worse it might be OK to try a log transformation on these explanatory variables. Log transformations are usually for violations of normality, but sometimes it can help with linearity and constant variance too. We also talked about dispersion parameters at the end of STAT 455, which can address violations of constant variance by accounting for overdispersion. There are also functions on the explanatory variables we could use to help with this, but this might be too complicated given that the issue is not too serious here / these really do not look bad.

To account for spatial correlation, I will first try to add a random effect for region. In order to do this, I first need to add a 'Region' column to my data frame.
```{r}
# adding a 'Region' column
regions <- read_csv("countriesregions.csv") # from: https://www.kaggle.com/datasets/fernandol/countries-of-the-world

countries_with_happy <- left_join(countries_with_happy, regions, by = c("Country_or_region" = "Country"))
countries_with_happy <-  countries_with_happy[, c("Happiness_score", "Country_or_region", "GDP", "Military", "Health", "Internet", "Unemployment", "Region")]

# filter countries with missing values for 'Region' column
countries_with_missing_region <- countries_with_happy %>% filter(is.na(Region))

# print countries with missing values for 'Region'
print(countries_with_missing_region)

# change name of variable in countries_with_happy dataset to match regions dataset in order to eliminate missing values for 'Region' col
countries_with_happy <- countries_with_happy %>%
  mutate(Region = ifelse(Country_or_region == 'Bosnia and Herzegovina', 'EASTERN EUROPE', Region))

# check to see how many missing values there are in each col
colSums(is.na(countries_with_happy)) # no missing values for country_or_region; 5 countries where the info about region is missing.
```

Now let's add the random effect for 'Region':
```{r}
lme_region <- lmer(Happiness_score ~ log(GDP) + Internet + Health + Military + Unemployment + (1 | Region), data = countries_with_happy)
summary(lme_region)
```

There is more variability in happiness scores between countries in the same region than between regions, after accounting for GDP, Internet, Health, Military, and Unemployment. Despite this, based off the question I am investigating and the nature of the data (with a potential violation of the independence assumption), it makes more sense to include a random effect for region.

### RANDOM FORESTS + VARIABLE IMPORTANCE MEASURES

```{r}
library(randomForest)

# Data investigation and preparation
str(countries_with_happy) # check types of variables
summary(countries_with_happy) # investigate data
dim(countries_with_happy) # check number of rows and columns - 137 rows, 9 columns

# Convert nominal categorical predictors from character to factor (Country_or_region, Region)
countries_with_happy$Country_or_region <- as.factor(countries_with_happy$Country_or_region)
countries_with_happy$Region <- as.factor(countries_with_happy$Region)

# Eliminate 'Country_or_region' variable (factor with 137 levels) - I previously got an error: 
countries_with_happy <- select(countries_with_happy, -Country_or_region)

# Impute missing values using rfImpute
countries_with_happy_imputed <- rfImpute(Happiness_score ~., countries_with_happy, ntree = 500) # not letting me; I have two many factor levels in countries

# Run the random forest model
set.seed(01242024)
rf <- randomForest(Happiness_score ~., data = countries_with_happy_imputed, ntree = 500)
print(rf)

# Find the optimal mtry value
# want to select the mtry value with the minimum out of bag (OOB) error

mtry <- tuneRF(countries_with_happy_imputed[-1], countries_with_happy_imputed$Happiness_score, ntreeTry = 500,stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1] 
print(mtry)
print(best.m)  

# Build model again using best mtry value
set.seed(01242024)
rf <- randomForest(Happiness_score ~ ., data = countries_with_happy_imputed, mtry = best.m, importance = TRUE, ntree = 500)
print(rf)

# Evaluate variable importance
importance(rf)
varImpPlot(rf)
```

From R Documentation: "The first [variable importance] measure is computed from permuting OOB data: For each tree, the prediction error on the out-of-bag portion of the data is recorded (error rate for classification, MSE for regression). Then the same is done after permuting each predictor variable. The difference between the two are then averaged over all trees, and normalized by the standard deviation of the differences. If the standard deviation of the differences is equal to 0 for a variable, the division is not done (but the average is almost always equal to 0 in that case).

The second measure is the total decrease in node impurities from splitting on the variable, averaged over all trees. For classification, the node impurity is measured by the Gini index. For regression, it is measured by residual sum of squares."

PERMUTATION IMPORTANCE:
```{r}
# Using DALEX package to implement permutation importance in R

install.packages("DALEX")
install.packages("randomForest")  # You can replace this with the package corresponding to your model
library(DALEX)
library(randomForest)

set.seed(123)
PI_model <- randomForest(Happiness_score ~ ., data = countries_with_happy_imputed)

# Create an explainer object
explainer <- explain(PI_model, data = countries_with_happy_imputed[,-which(names(countries_with_happy_imputed) == "Happiness_score")], y = countries_with_happy_imputed$Happiness_score)

# Calculate Permutation Importance
perm_importance <- feature_importance(explainer, loss_function = DALEX::loss_root_mean_square, type = "variable_importance")

# Print the results
print(perm_importance)

# Plot the permutation importance
plot(perm_importance)
```

Is this the same as the previous graph on the left (%IncMSE)?

CONDITIONAL IMPORTANCE:
```{r}
library(party)
set.seed(01292024)

# countries_ci <- cforest(data = countries_with_happy_imputed, Happiness_score ~., control = cforest_unbiased())
# cond_imp <- varimp(countries_ci, conditional = TRUE) # store conditional variable importance scores in cond_imp
# cond_imp <- ifelse(cond_imp < 0, 0, cond_imp) # if CI score is negative, convert it to 0, else keep it the same
# cond_imp_as_perc <- cond_imp/sum(cond_imp) * 100 
# print(cond_imp_as_perc)
```

^ Having trouble with my code for CI

SHAPLEY:

(to be continued)